
# ğŸ§  Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning

This repository contains the **official code** for the paper
***Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning***.

The code supports **evaluation**, **failure-prefix dataset construction**, and **RLVR training via GRPO**, using **TRL**, **vLLM**, **DeepSpeed**, and **Accelerate**.

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ environment.yml          # Conda environment definition
â”œâ”€â”€ zero3.yaml               # Accelerate + DeepSpeed (ZeRO-3) config
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                    # Failure-prefix-conditioned datasets
â”‚   â”œâ”€â”€ iteration1_target_acc_25.csv
â”‚   â”œâ”€â”€ iteration1_target_acc_50.csv
â”‚   â”œâ”€â”€ iteration1_target_acc_75.csv
â”‚   â””â”€â”€ iteration2_target_acc_50.csv
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ eval_config.yaml     # Evaluation configuration
â”‚   â””â”€â”€ evaluation.py        # Evaluation runner
â””â”€â”€ train/
    â”œâ”€â”€ GRPO_config.yaml     # GRPO / RLVR training config
    â””â”€â”€ GRPO_trainer.py      # Training entry point
```

---

## âš™ï¸ Environment Setup

Create and activate the Conda environment:

```bash
conda env create -f environment.yml
conda activate failure-prefix-conditioning
```

### Requirements

* CUDA-enabled GPUs
* [DeepSpeed](https://www.deepspeed.ai/)
* ğŸ¤— `accelerate` (configured for your cluster / node setup)
* vLLM (for fast multi-process inference)

---

## ğŸš€ How to Run

### ğŸ” Evaluation

Run evaluation using the provided YAML config:

```bash
python eval/evaluation.py --config eval_config.yaml
```

This script measures rollout accuracy and recovery behavior under prefix conditioning.

---

### ğŸ¯ RLVR Training (GRPO via TRL + vLLM)

We perform **Reinforcement Learning with Verifiable Rewards (RLVR)** using **Group Relative Policy Optimization (GRPO)**.

* **TRL** handles policy optimization
* **vLLM** is used for fast, parallel rollout generation during reward evaluation
* **DeepSpeed ZeRO-3** enables efficient large-model training

Launch training with:

```bash
accelerate launch \
  --config_file zero3.yaml \
  --num_processes <NUM_PROCESSES> \
  train/GRPO_trainer.py \
  --config GRPO_config.yaml
```

Replace `<NUM_PROCESSES>` with the number of GPU processes available.

---

## ğŸ§ª Failure-Prefix-Conditioned Datasets

The `data/` directory contains curated datasets used to study learning on **saturated problems**.
File names directly encode the construction iteration and target rollout accuracy threshold ( \tau ).

| Dataset file                   | Description                                                         |
| ------------------------------ | ------------------------------------------------------------------- |
| `iteration1_target_acc_25.csv` | Iteration 1, target accuracy ( \tau = 0.25 )                        |
| `iteration1_target_acc_50.csv` | Iteration 1, target accuracy ( \tau = 0.50 ) **(main setting)**     |
| `iteration1_target_acc_75.csv` | Iteration 1, target accuracy ( \tau = 0.75 )                        |
| `iteration2_target_acc_50.csv` | Iteration 2, ( \tau = 0.50 ), iterative failure-prefix conditioning |

These datasets differ only in the saturation threshold and conditioning iteration, enabling controlled comparisons.

---
